{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dominic/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1.10.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn import model_selection as ms\n",
    "from sklearn import preprocessing as pp\n",
    "import numpy as np\n",
    "\n",
    "print('1')\n",
    "print(tf.__version__)\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "def tryLabelEncoder(df):\n",
    "    for column in df.columns:\n",
    "       if df[column].dtype == type(object):\n",
    "            le = pp.LabelEncoder()\n",
    "            df[column] = le.fit_transform(df[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  l1_ratio   alpha  max_iter  random_state  n_jobs  n_samples  \\\n",
      "0   0  0.304083  0.0001       417           475      -1       1089   \n",
      "1   1  0.727744  0.0010       578           569       1        790   \n",
      "2   2  0.745885  0.0100       588           529       2        428   \n",
      "3   3  0.474605  0.0010       829           103       4        877   \n",
      "4   4  0.395049  0.0010       167           418       2        216   \n",
      "\n",
      "   n_features  n_classes  n_clusters_per_class  n_informative    flip_y  \\\n",
      "0         327          4                     3              7  0.074798   \n",
      "1         373          4                     5              7  0.077781   \n",
      "2        1198          2                     5              6  0.030196   \n",
      "3         313          6                     5              7  0.057261   \n",
      "4         644          8                     5             11  0.073728   \n",
      "\n",
      "       scale      time  penalty_elasticnet  penalty_l1  penalty_l2  \n",
      "0  24.242009  0.409987                   0           0           0  \n",
      "1  54.626302  3.950953                   0           1           0  \n",
      "2  17.999964  0.368702                   0           0           0  \n",
      "3  82.257222  1.004559                   0           0           0  \n",
      "4  95.515601  0.802800                   1           0           0  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing as pp\n",
    "\n",
    "# Train Data\n",
    "train = 'train.csv'\n",
    "test = 'test.csv'\n",
    "na  = 'missing'\n",
    "#'n_samples','n_features','n_classes','n_clusters_per_class','n_informative','flip_y','scale' \n",
    "#'penalty','l1_ratio','alpha','max_iter','random_state','n_jobs'\n",
    "train_data = pd.read_csv(train,na_values='none')\n",
    "train_data = pd.get_dummies(train_data)\n",
    "test_data = pd.read_csv(test,na_values='none')\n",
    "test_data = pd.get_dummies(test_data)\n",
    "print(train_data.head())\n",
    "# print (train_data.head())\n",
    "# print (test_data.head())\n",
    "temp = train_data.fillna(na)\n",
    "# tryLabelEncoder(temp)\n",
    "X_train = temp.drop(['time','id'],axis=1).values\n",
    "Y_train = train_data['time'].values\n",
    "Y_train = Y_train.ravel()\n",
    "\n",
    "# Test Data\n",
    "ID = test_data['id'].values\n",
    "temp = test_data.fillna(na)\n",
    "# tryLabelEncoder(temp)\n",
    "TEST = temp.drop(['id'],axis=1).values\n",
    "# print(X_train)\n",
    "# print(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id  l1_ratio   alpha  max_iter  random_state  n_jobs  n_samples  \\\n",
      "0   0  0.304083  0.0001       417           475      -1       1089   \n",
      "1   1  0.727744  0.0010       578           569       1        790   \n",
      "2   2  0.745885  0.0100       588           529       2        428   \n",
      "3   3  0.474605  0.0010       829           103       4        877   \n",
      "4   4  0.395049  0.0010       167           418       2        216   \n",
      "\n",
      "   n_features  n_classes  n_clusters_per_class  n_informative    flip_y  \\\n",
      "0         327          4                     3              7  0.074798   \n",
      "1         373          4                     5              7  0.077781   \n",
      "2        1198          2                     5              6  0.030196   \n",
      "3         313          6                     5              7  0.057261   \n",
      "4         644          8                     5             11  0.073728   \n",
      "\n",
      "       scale      time  penalty_elasticnet  penalty_l1  penalty_l2  \n",
      "0  24.242009  0.409987                   0           0           0  \n",
      "1  54.626302  3.950953                   0           1           0  \n",
      "2  17.999964  0.368702                   0           0           0  \n",
      "3  82.257222  1.004559                   0           0           0  \n",
      "4  95.515601  0.802800                   1           0           0  \n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "[[  0.43786681   0.0001     997.         ...   0.           0.\n",
      "    0.        ]\n",
      " [  0.81140953   0.01       638.         ...   0.           0.\n",
      "    1.        ]\n",
      " [  0.12520034   0.0001     711.         ...   0.           1.\n",
      "    0.        ]\n",
      " ...\n",
      " [  0.81609605   0.001      251.         ...   0.           0.\n",
      "    1.        ]\n",
      " [  0.38643597   0.01       202.         ...   0.           1.\n",
      "    0.        ]\n",
      " [  0.26836232   0.001      938.         ...   0.           0.\n",
      "    1.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Step0. Pre-processing\n",
    "# 调用fit方法，根据已有的训练数据创建一个标准化的转换器\n",
    "\n",
    "# penalty = temp['penalty'].unique()\n",
    "# rule = []\n",
    "# i = 0\n",
    "# for p in penalty:\n",
    "#     rule.append([p,i])\n",
    "#     i += 1\n",
    "# print(rule)\n",
    "\n",
    "# for r in X_train:\n",
    "#     if r[0] == rule[0][0]: r[0] = rule[0][1]\n",
    "#     elif r[0] == rule[1][0]: r[0] = rule[1][1]\n",
    "#     elif r[0] == rule[2][0]: r[0] = rule[2][1]\n",
    "#     elif r[0] == rule[3][0]: r[0] = rule[3][1]\n",
    " \n",
    "scaler = pp.StandardScaler().fit(X_train)\n",
    "# scaler = pp.RobustScaler(with_centering=False).fit(X_train,with_centering=False)\n",
    "print(scaler)\n",
    "# X_train = scaler.transform(X_train)\n",
    "# print(X_train)\n",
    "\n",
    "X = X_train\n",
    "Y = Y_train\n",
    "\n",
    "# Spliting Training Data, Training Test Data and Validation Data\n",
    "X_train,X_tmp,Y_train,Y_tmp = ms.train_test_split(X,Y,test_size = 0.2,random_state =13)\n",
    "X_test,X_val,Y_test,Y_val = ms.train_test_split(X_tmp,Y_tmp,test_size = 0.2,random_state =13)\n",
    "\n",
    "# X is train data X, Y is train data Y\n",
    "\n",
    "# for r in TEST:\n",
    "#     if r[0] == rule[0][0]: r[0] = rule[0][1]\n",
    "#     elif r[0] == rule[1][0]: r[0] = rule[1][1]\n",
    "#     elif r[0] == rule[2][0]: r[0] = rule[2][1]\n",
    "#     elif r[0] == rule[3][0]: r[0] = rule[3][1]\n",
    "        \n",
    "TEST = scaler.transform(TEST)\n",
    "# TEST is TEST DATA X\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.5905982918682047\n"
     ]
    }
   ],
   "source": [
    "# ##################################################\n",
    "# ##################################################\n",
    "#######XGBOOST Model#######################################\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV  #grid search\n",
    "from xgboost.sklearn import XGBRegressor\n",
    "import xgboost as xgb\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "def adjustParas(param_test,XGB):\n",
    "    gsearch = GridSearchCV(estimator = XGB, \n",
    "                           param_grid = param_test1,scoring='roc_auc',n_jobs=4,iid=False, cv=5) \n",
    "    gsearch.fit(X_train,Y_train)\n",
    "    gsearch.grid_scores_, gsearch.best_params_, gsearch.best_score_\n",
    "\n",
    "# xgb_param = XGB.get_xgb_params()\n",
    "# xgtrain = xgb.DMatrix(X_train, label=Y_train)\n",
    "# cv_folds = 5\n",
    "# early_stopping_rounds = 50\n",
    "# cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=XGB.get_params()['n_estimators'], nfold=cv_folds,\n",
    "#     early_stopping_rounds=early_stopping_rounds)\n",
    "# print(\"best 'n_estimators':\",cvresult.shape[0])\n",
    "# XGB.set_params(n_estimators=cvresult.shape[0])\n",
    "\n",
    "\n",
    "# param_test1 = {\n",
    "#  'max_depth':range(3,10,2),\n",
    "#  'min_child_weight':range(1,6,2)\n",
    "# }\n",
    "# adjustParas(param_test1,XGB)\n",
    "\n",
    "# param_test2 = {\n",
    "#  'max_depth':[4,5,6],\n",
    "#  'min_child_weight':[4,5,6]\n",
    "# }\n",
    "# adjustParas(param_test2,XGB)\n",
    "\n",
    "\n",
    "# param_test3 = {\n",
    "#  'gamma':[i/10.0 for i in range(0,5)]\n",
    "# }\n",
    "# adjustParas(param_test3,XGB)\n",
    "\n",
    "\n",
    "# param_test4 = {\n",
    "#  'subsample':[i/10.0 for i in range(6,10)],\n",
    "#  'colsample_bytree':[i/10.0 for i in range(6,10)]\n",
    "# }\n",
    "# adjustParas(param_test4,XGB)\n",
    "\n",
    "\n",
    "# param_test5 = {\n",
    "#  'subsample':[i/100.0 for i in range(75,90,5)],\n",
    "#  'colsample_bytree':[i/100.0 for i in range(75,90,5)]\n",
    "# }\n",
    "# adjustParas(param_test5,XGB)\n",
    "\n",
    "\n",
    "# param_test6 = {\n",
    "#  'reg_alpha':[1e-5, 1e-2, 0.1, 1, 100]\n",
    "# }\n",
    "# adjustParas(param_test6,XGB)\n",
    "\n",
    "\n",
    "# param_test7 = {\n",
    "#  'reg_alpha':[0, 0.001, 0.005, 0.01, 0.05]\n",
    "# }\n",
    "# adjustParas(param_test7,XGB)\n",
    "\n",
    "\n",
    "# print('done')\n",
    "\n",
    "# XGB = XGBRegressor(learning_rate =0.007,max_depth=6,min_child_weight=0,gamma=0,\n",
    "#                    subsample=0.8,colsample_bytree=0.8,reg_alpha=0,\n",
    "#                    n_estimators=1000,objective= 'reg:linear',nthread=4,\n",
    "#                    scale_pos_weight=1,seed=30,target = 'Disbursed',IDcol = 'ID')\n",
    "                   \n",
    "# XGB.fit(X_train,Y_train,eval_metric='auc')\n",
    "# predictions = XGB.predict(X_test)\n",
    "# mse = ((Y_test - predictions) ** 2).mean(axis=0)\n",
    "# print (\"MSE : %.4g\" % mse)\n",
    "\n",
    "\n",
    "# pre = XGB.predict(TEST)\n",
    "# print(pre)\n",
    "\n",
    "##Another test:\n",
    "params = {'min_child_weight':[0,1,2,3], 'gamma':[i/10.0 for i in range(0,6)],  'subsample':[0.8],\n",
    "'colsample_bytree':[0.8], 'max_depth': [2,3,4],'learning_rate':[0.0005,0.00001,0.00005,0.00001]}\n",
    "\n",
    "# Initialize XGB and GridSearch\n",
    "xgb = XGBRegressor(nthread=-1) \n",
    "\n",
    "grid = GridSearchCV(xgb, params)\n",
    "grid.fit(X_train, Y_train)\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Print the r2 score\n",
    "print(r2_score(Y_val, grid.best_estimator_.predict(X_val))) \n",
    "\n",
    "pre = grid.best_estimator_.predict(TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE : 1.297\n",
      "[ 0.10115477  1.6192045  -0.12277973 -0.11765504  0.30448192  1.5818298\n",
      " -0.12177831  0.09265903  0.14085537 -0.12177831  0.00807503  0.88607216\n",
      " -0.1254934   0.45554304  0.99332356  0.75144434  0.7909187   0.30041486\n",
      "  1.646663    0.2981587   0.7577449  -0.144813    0.02835214  0.67775154\n",
      "  0.5358447  -0.296708    1.0278287   0.4790691   0.51109993 -0.21702987\n",
      "  0.51109993  0.56017035 -0.28779054  0.6562432   0.97090256  1.6996697\n",
      "  1.0693197   0.32946062  0.23822221 -0.09618938  1.1442604   0.72158027\n",
      "  0.33639616 -0.10604578  0.47710085  0.72158027  1.1261207  -0.12781495\n",
      " -0.14993781  0.08631095 -0.14627069  1.2378552  -0.12409997  1.6478484\n",
      "  0.01437554 -0.22557217  0.40738678  0.1182439   0.47179604  0.4762948\n",
      " -0.1254934   1.8169764  -0.25097477  0.17390159  1.783718    0.7232448\n",
      "  0.4208628  -0.10092098  1.5125655   0.00807503 -0.3089673  -0.1254934\n",
      "  0.75403976  0.56096697  1.7077149   0.00807503  0.03465265 -0.29042578\n",
      "  1.6478484  -0.14993781  0.14924872  0.7577449   0.23822221  0.93506825\n",
      "  0.7634442   0.24076155  1.1442604  -0.06643325  0.45554304  0.03465265\n",
      "  1.7364492  -0.14993781  0.3012203   1.4813719   0.00807503 -0.144813\n",
      "  0.56017035 -0.24167806  0.37526974 -0.1951446 ]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "320/320 [==============================] - 1s 2ms/step - loss: 11.4135 - acc: 0.0000e+00\n",
      "Epoch 2/1000\n",
      "320/320 [==============================] - 0s 406us/step - loss: 10.3257 - acc: 0.0000e+00\n",
      "Epoch 3/1000\n",
      "320/320 [==============================] - 0s 346us/step - loss: 10.3257 - acc: 0.0000e+00\n",
      "Epoch 4/1000\n",
      "320/320 [==============================] - 0s 353us/step - loss: 10.3257 - acc: 0.0000e+00\n",
      "Epoch 5/1000\n",
      "320/320 [==============================] - 0s 344us/step - loss: 10.3257 - acc: 0.0000e+00\n",
      "Epoch 6/1000\n",
      "320/320 [==============================] - 0s 345us/step - loss: 10.3257 - acc: 0.0000e+00\n",
      "Epoch 7/1000\n",
      "320/320 [==============================] - 0s 334us/step - loss: 10.3257 - acc: 0.0000e+00\n",
      "Epoch 8/1000\n",
      "320/320 [==============================] - 0s 357us/step - loss: 10.3257 - acc: 0.0000e+00\n",
      "Epoch 9/1000\n",
      "320/320 [==============================] - 0s 373us/step - loss: 10.3257 - acc: 0.0000e+00\n",
      "Epoch 10/1000\n",
      "320/320 [==============================] - 0s 333us/step - loss: 10.3257 - acc: 0.0000e+00\n",
      "Epoch 11/1000\n",
      "320/320 [==============================] - 0s 333us/step - loss: 10.3257 - acc: 0.0000e+00\n",
      "Epoch 12/1000\n",
      "320/320 [==============================] - 0s 368us/step - loss: 10.3257 - acc: 0.0000e+00\n",
      "Epoch 13/1000\n",
      "320/320 [==============================] - 0s 354us/step - loss: 10.3257 - acc: 0.0000e+00\n",
      "Epoch 14/1000\n",
      "320/320 [==============================] - 0s 330us/step - loss: 10.3257 - acc: 0.0000e+00\n",
      "Epoch 15/1000\n",
      "320/320 [==============================] - 0s 344us/step - loss: 10.3257 - acc: 0.0000e+00\n",
      "Epoch 16/1000\n",
      "320/320 [==============================] - 0s 485us/step - loss: 10.3257 - acc: 0.0000e+00\n",
      "Epoch 17/1000\n",
      "320/320 [==============================] - 0s 438us/step - loss: 10.3257 - acc: 0.0000e+00\n",
      "Epoch 18/1000\n",
      "320/320 [==============================] - 0s 350us/step - loss: 10.3257 - acc: 0.0000e+00\n",
      "Epoch 19/1000\n",
      "320/320 [==============================] - 0s 336us/step - loss: 10.3257 - acc: 0.0000e+00\n",
      "Epoch 20/1000\n",
      "320/320 [==============================] - 0s 334us/step - loss: 10.3257 - acc: 0.0000e+00\n",
      "Epoch 21/1000\n",
      "320/320 [==============================] - 0s 339us/step - loss: 10.3257 - acc: 0.0000e+00\n",
      "Epoch 22/1000\n",
      "320/320 [==============================] - 0s 351us/step - loss: 10.3257 - acc: 0.0000e+00\n",
      "Epoch 23/1000\n",
      "320/320 [==============================] - 0s 359us/step - loss: 10.3257 - acc: 0.0000e+00\n",
      "Epoch 24/1000\n",
      "320/320 [==============================] - 0s 347us/step - loss: 10.3257 - acc: 0.0000e+00\n",
      "Epoch 25/1000\n",
      "320/320 [==============================] - 0s 340us/step - loss: 10.3257 - acc: 0.0000e+00\n",
      "Epoch 26/1000\n",
      "320/320 [==============================] - 0s 379us/step - loss: 10.3257 - acc: 0.0000e+00\n",
      "Epoch 27/1000\n",
      "320/320 [==============================] - 0s 360us/step - loss: 10.3257 - acc: 0.0000e+00\n",
      "Epoch 28/1000\n",
      "320/320 [==============================] - 0s 350us/step - loss: 10.3257 - acc: 0.0000e+00\n",
      "Epoch 29/1000\n",
      "320/320 [==============================] - 0s 346us/step - loss: 10.3257 - acc: 0.0000e+00\n",
      "Epoch 30/1000\n",
      "320/320 [==============================] - 0s 359us/step - loss: 10.3257 - acc: 0.0000e+00\n",
      "Epoch 31/1000\n",
      "320/320 [==============================] - 0s 476us/step - loss: 10.3257 - acc: 0.0000e+00\n",
      "Epoch 32/1000\n",
      "320/320 [==============================] - 0s 456us/step - loss: 10.3257 - acc: 0.0000e+00\n",
      "Epoch 33/1000\n",
      "320/320 [==============================] - 0s 445us/step - loss: 10.3257 - acc: 0.0000e+00\n",
      "Epoch 34/1000\n",
      "320/320 [==============================] - 0s 456us/step - loss: 10.3257 - acc: 0.0000e+00\n",
      "Epoch 35/1000\n",
      "320/320 [==============================] - 0s 396us/step - loss: 10.3257 - acc: 0.0000e+00\n",
      "Epoch 36/1000\n",
      "320/320 [==============================] - 0s 445us/step - loss: 10.3257 - acc: 0.0000e+00\n",
      "Epoch 37/1000\n",
      "320/320 [==============================] - 0s 425us/step - loss: 10.3257 - acc: 0.0000e+00\n",
      "Epoch 38/1000\n",
      "320/320 [==============================] - 0s 539us/step - loss: 10.3257 - acc: 0.0000e+00\n",
      "Epoch 39/1000\n",
      "320/320 [==============================] - 0s 394us/step - loss: 10.3257 - acc: 0.0000e+00\n",
      "Epoch 40/1000\n",
      "320/320 [==============================] - 0s 401us/step - loss: 10.3257 - acc: 0.0000e+00\n",
      "Epoch 41/1000\n",
      "320/320 [==============================] - 0s 371us/step - loss: 10.3257 - acc: 0.0000e+00\n",
      "Epoch 42/1000\n",
      "320/320 [==============================] - 0s 366us/step - loss: 10.3257 - acc: 0.0000e+00\n",
      "Epoch 43/1000\n",
      "320/320 [==============================] - 0s 368us/step - loss: 10.3257 - acc: 0.0000e+00\n",
      "Epoch 44/1000\n",
      "320/320 [==============================] - 0s 451us/step - loss: 10.3257 - acc: 0.0000e+00\n",
      "Epoch 45/1000\n",
      "320/320 [==============================] - 0s 447us/step - loss: 10.3257 - acc: 0.0000e+00\n",
      "Epoch 46/1000\n",
      "320/320 [==============================] - 0s 397us/step - loss: 10.3257 - acc: 0.0000e+00\n",
      "Epoch 47/1000\n",
      "320/320 [==============================] - 0s 468us/step - loss: 10.3257 - acc: 0.0000e+00\n",
      "Epoch 48/1000\n",
      "320/320 [==============================] - 0s 458us/step - loss: 10.3257 - acc: 0.0000e+00\n",
      "Epoch 49/1000\n",
      "320/320 [==============================] - 0s 470us/step - loss: 10.3257 - acc: 0.0000e+00\n",
      "Epoch 50/1000\n",
      "320/320 [==============================] - 0s 432us/step - loss: 10.3257 - acc: 0.0000e+00\n",
      "Epoch 51/1000\n",
      "320/320 [==============================] - 0s 436us/step - loss: 10.3257 - acc: 0.0000e+00\n",
      "Epoch 52/1000\n",
      "320/320 [==============================] - 0s 379us/step - loss: 10.3257 - acc: 0.0000e+00\n",
      "Epoch 53/1000\n",
      "320/320 [==============================] - 0s 456us/step - loss: 10.3257 - acc: 0.0000e+00\n",
      "Epoch 54/1000\n",
      "320/320 [==============================] - 0s 442us/step - loss: 10.3257 - acc: 0.0000e+00\n",
      "Epoch 55/1000\n",
      "320/320 [==============================] - 0s 374us/step - loss: 10.3257 - acc: 0.0000e+00\n",
      "Epoch 56/1000\n",
      "320/320 [==============================] - 0s 380us/step - loss: 10.3257 - acc: 0.0000e+00\n",
      "Epoch 57/1000\n",
      "320/320 [==============================] - 0s 425us/step - loss: 10.3257 - acc: 0.0000e+00\n",
      "Epoch 58/1000\n",
      "320/320 [==============================] - 0s 366us/step - loss: 10.3257 - acc: 0.0000e+00\n",
      "Epoch 59/1000\n",
      "320/320 [==============================] - 0s 398us/step - loss: 10.3257 - acc: 0.0000e+00\n",
      "Epoch 60/1000\n",
      " 32/320 [==>...........................] - ETA: 0s - loss: 12.5923 - acc: 0.0000e+00"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-f0e0f2fdc8a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m               metrics=['accuracy'])\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1361\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1362\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1363\u001b[0;31m           validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1365\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    262\u001b[0m           \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m           \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2912\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_arrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_symbols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2914\u001b[0;31m     \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2915\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2916\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# # ##################################################\n",
    "# # ##################################################\n",
    "# #######Model#######################################\n",
    "# # # Data from Tensorflow Toturials\n",
    "\n",
    "# # # mnist = tf.keras.datasets.mnist\n",
    "\n",
    "x_train = X_train\n",
    "y_train = Y_train\n",
    "\n",
    "x_test = X_test\n",
    "y_test = Y_test\n",
    "\n",
    "# (x_train, y_train),(x_test, y_test) = x_train,y_train\n",
    "# x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "#   tf.keras.layers.Dropout(0.2),\n",
    "#   tf.keras.layers.Dense(42, activation=tf.nn.softmax)\n",
    "    tf.keras.layers.Dense(42, activation=tf.nn.softmax)\n",
    "\n",
    "])\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=1000)\n",
    "model.evaluate(x_test, y_test)\n",
    "print(model)\n",
    "pre = model.predict(TEST)\n",
    "print(pre)\n",
    "# # ##################################################\n",
    "# # ##################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'tf_wx_model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x1a2b3843c8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dominic/anaconda3/lib/python3.6/site-packages/tensorflow/python/estimator/inputs/pandas_io.py:106: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if target_column in x:\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'index'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-131-2eb9bfa314b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mSTEPS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m400\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mregressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwx_input_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSTEPS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     evaluations.append(regressor.evaluate(input_fn=wx_input_fn(X_val,\n\u001b[1;32m     20\u001b[0m                                                                \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-131-2eb9bfa314b6>\u001b[0m in \u001b[0;36mwx_input_fn\u001b[0;34m(X, y, num_epochs, shuffle, batch_size)\u001b[0m\n\u001b[1;32m     11\u001b[0m                                                \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                                               \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m                                               batch_size=batch_size)\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mevaluations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/estimator/inputs/pandas_io.py\u001b[0m in \u001b[0;36mpandas_input_fn\u001b[0;34m(x, y, batch_size, num_epochs, shuffle, queue_capacity, num_threads, target_column)\u001b[0m\n\u001b[1;32m    108\u001b[0m           \u001b[0;34m'Cannot use name %s for target column: DataFrame already has a '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m           'column with that name: %s' % (target_column, x.columns))\n\u001b[0;32m--> 110\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray_equal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m       raise ValueError('Index for x and y are mismatched.\\nIndex for x: %s\\n'\n\u001b[1;32m    112\u001b[0m                        'Index for y: %s\\n' % (x.index, y.index))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'index'"
     ]
    }
   ],
   "source": [
    "feature_cols = ['penalty','l1_ratio','alpha','max_iter',\n",
    "                'random_state','n_jobs','n_samples','n_features',\n",
    "                'n_classes','n_clusters_per_class','n_informative',\n",
    "                'flip_y','scale']\n",
    "\n",
    "regressor = tf.estimator.DNNRegressor(feature_columns=feature_cols,\n",
    "                                      hidden_units=[50,50],\n",
    "                                     model_dir='tf_wx_model')\n",
    "def wx_input_fn(X,y=None,num_epochs=None,shuffle=True,batch_size=20):\n",
    "    return tf.estimator.inputs.pandas_input_fn(x=X,y=y,\n",
    "                                               num_epochs=num_epochs,\n",
    "                                              shuffle=shuffle,\n",
    "                                              batch_size=batch_size)\n",
    "\n",
    "evaluations = []\n",
    "STEPS = 400\n",
    "for i in range(100):\n",
    "    regressor.train(input_fn=wx_input_fn(X_train,y=Y_train),steps=STEPS)\n",
    "    evaluations.append(regressor.evaluate(input_fn=wx_input_fn(X_val,\n",
    "                                                               y_val,\n",
    "                                                               num_epochs=1,\n",
    "                                                               shuffle=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre = model.predict(TEST)\n",
    "# Step3. Output file\n",
    "with open ('xgbtraintest.csv','w') as file:\n",
    "    file.write('Id,Time\\n')\n",
    "    for i in range(0,len(pre)):\n",
    "        file.write(str(ID[i]))\n",
    "        file.write(',')\n",
    "        if pre[i] < 0:\n",
    "            file.write('0')\n",
    "            file.write('\\n')\n",
    "        else:\n",
    "            file.write(str(pre[i]))\n",
    "            file.write('\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
